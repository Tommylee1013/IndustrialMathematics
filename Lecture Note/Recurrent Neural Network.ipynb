{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "순환 신경망을 이용한 Sequence Data Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "321c3c30338f0832"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sequence Data\n",
    "- 순서를 고려한 데이터\n",
    "- 원소들이 특정한 순서를 가지며 상호 독립적이지 않다\n",
    "- 시퀀스 데이터의 좋은 예는 시계열 데이터이다\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1400/1*aIT6tmnk3qHpStkOX3gGcQ.png\" alt=\"My Image\"></center>\n",
    "\n",
    "#### 시퀀스 모델링의 종류\n",
    "\n",
    "- **Many to One** : 입력 데이터는 시퀀스, 출력은 벡터 (ex : 감성분석 - 입력은 텍스트, 출력은 label)\n",
    "- **One to Many** : 입력 데이터는 일반적인 형태, 출력은 시퀀스 (ex : 이미지 캡셔닝 - 입력은 이미지, 출력이 모두 시퀀스)\n",
    "- **Many to Many** : 입력, 출력이 모두 시퀀스인 모형\n",
    "    - 입력과 출력이 동기적인지 아닌지에 따라 나눠짐\n",
    "    - 동기적 모델– 각 프레임이 레이블되어 있는 비디오 분류\n",
    "    - 비동기적 모델– 한 언어에서 다른 언어로 번역 작업\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11b3b71f330c89cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RNN Network\n",
    "\n",
    "$$\\mathbf{z}_h^{(t)} = \\mathbf{W}_{xh}\\mathbf{x}^{(t)} + \\mathbf{W}_{hh}\\mathbf{h}^{(t-1)} + \\mathbf{b}_h$$\n",
    "$$\\mathbf{h}^{(t)} = \\phi_h \\Big( \\mathbf{z}_h^{(t)}\\Big) = \\phi_h \\Big( \\mathbf{W}_{xh} \\mathbf{x}^{(t)} + \\mathbf{W}_{hh}\\mathbf{h}^{(t-1)} + \\mathbf{b}_h\\Big)$$\n",
    "$$\\mathbf{h}^{(t)} = \\phi_h \\Big( \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{W}_{xh} ; \\mathbf{W}_{hh}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x}^{(t)} \\\\\n",
    "\\mathbf{h}^{(t-1)} \\\\\n",
    "\\end{bmatrix}\n",
    " + \\mathbf{b}_h \\Big)$$\n",
    "\n",
    "$$\\mathbf{Ax} = \\begin{bmatrix}\n",
    "\\mathbf{a}_1 & \\cdots & \\mathbf{a}_2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x}_{1} \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{x}_{n} \\\\\n",
    "\\end{bmatrix} = \n",
    "\\mathbf{x}_{1}\\mathbf{a}_{1} + \\mathbf{x}_{2}\\mathbf{a}_{2} + \\cdots + \\mathbf{x}_{n}\\mathbf{a}_{n}$$\n",
    "\n",
    "**Sequence Gradient Problem**\n",
    "\n",
    "$$\\frac{\\partial L^{(t)}}{\\partial \\mathbf{W}_{hh}} = \n",
    "\\frac{\\partial L^{(t)}}{\\partial \\mathbf{y}^{(t)}} \\cdot \\frac{\\partial \\mathbf{y}^{(t)}}{\\partial \\mathbf{h}^{(t)}} \\cdot \n",
    "\\Big( \\sum_{k=1}^t \\frac{\\partial \\mathbf{h}^{(t)}}{{\\partial \\mathbf{h}^{(k)}}}\n",
    "\\cdot \\frac{\\partial \\mathbf{h}^{(t)}}{{\\partial \\mathbf{W}_{(hh)}}}\\Big)$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a22b9144f93fe409"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Long Short Term Memory (LSTM)\n",
    "- LSTM은 그래디언트 소실 문제를 극복하기 위해 소개됨\n",
    "- 기본 구성 요소는 은닉층을 의미하는 memory cell\n",
    "- 그래디언트 소실, 폭주 문제 해결을 위해 각 메모리셀에 적절한 가중치 w=1을 유지하는 순환에지가 존재, 이 순환에지의 출력을 cell state라고 함.\n",
    "- 세종류의 게이트 : 삭제게이트, 입력게이트, 출력게이트가 있음\n",
    "\n",
    "**forgot gate**\n",
    "\n",
    "$$\\mathbf{f}_t = \\sigma\\Big( \n",
    "\\mathbf{W}_{(xf)} \\mathbf{x}^{(t)} + \\mathbf{W}_{(hf)} \\mathbf{h}^{(t-1)} + \\mathbf{b}_{(f)}\n",
    "\\Big)$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bfc0674bb77df2c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
